{
  "cache_key": "review::Agentic AI architecture for mobile apps::sources=8::len=10895",
  "value": {
    "pass": false,
    "issues": [
      "Costs and schedule are not concretely addressed: no estimates, tables, or timelines; TL;DR claims they are addressed but the body only provides principles.",
      "Options/evaluation section outlines approach but provides no applied comparison, decision matrix, benchmarks, or empirical evidence supporting the recommendation.",
      "Mobile-specific engineering details are under-specified: on-device vs server inference tradeoffs, app lifecycle/background execution, offline/poor-network handling, energy/thermal budgets, and memory/footprint constraints.",
      "Tooling surface lacks concrete examples and enforceable schemas: no JSON Schemas, versioning/migration plan details, or exemplar tools (calendar/contacts/messaging) with permissions and dry-run/undo semantics.",
      "Safety/threat model gaps: no treatment of prompt or tool-output injection, data exfiltration via tools, compromised/jailbroken devices, or abuse scenarios; rollback semantics for multi-step side effects are not concretely defined.",
      "Performance and cost targets are missing: no latency SLOs per step, explicit token/context budgets, loop-iteration caps with values, rate-limit/backoff strategy, or cost projections for representative tasks/backends.",
      "Security architecture incomplete: lacks authN/authZ model for tool invocations, secrets management/rotation, certificate pinning or mTLS, keychain/secure enclave usage, and supply-chain considerations.",
      "Privacy/compliance omissions: no data classification/retention policy, on-device vs server data residency, GDPR/CCPA DSR handling, or explicit consent flows for telemetry.",
      "Observability plan lacks specifics on redaction rules, consent tracking, offline buffering/retry on mobile, and event/log volume limits to protect battery and data usage.",
      "Testing plan misses adversarial evaluations (prompt/tool injection), battery/thermal profiling, network variability (airplane mode, captive portals), and model-switch regression testing via the gateway.",
      "Rollout plan lacks staffing/ownership, phase exit criteria with quantitative thresholds, explicit success metrics, risk register, and release/feature-flag rollback plans.",
      "References are mostly report-writing guides; technical claims about agent reliability/architecture are uncited, and two sources are explicitly non-content-bearing (S2, S4), weakening evidentiary support."
    ],
    "new_queries": [
      "Provide concrete cost model: candidate model backends (and on-device options), price per token/call, expected tokens per task, DAU/QPS assumptions, and monthly cost projections with sensitivity.",
      "Define latency SLOs per loop step (plan, tool run, reflect) and end-to-end targets under Wiâ€‘Fi/LTE/poor-network conditions.",
      "Decide deployment topology for launch (client-only vs client+gateway) and justify with privacy, performance, and maintainability tradeoffs.",
      "List initial tool categories (e.g., calendar, contacts, messages, files, web fetch) with JSON Schemas (params/responses), permission gates, dry-run/preview, and concrete undo/compensation semantics.",
      "Detail app lifecycle handling: background execution limits (iOS/Android), task resumption/cancellation, notifications for approvals, and offline queueing/retry policies.",
      "Specify on-device vs server inference criteria: model sizes, memory/CPU/GPU/NPU budgets, energy/thermal targets, and fallback behavior.",
      "Provide security architecture: authN/authZ for tools (OAuth/device auth), secrets storage/rotation, mTLS/cert pinning, keychain/secure enclave usage, code signing/supply-chain controls.",
      "Add privacy/compliance plan: data classification, retention/expiration, on-device encryption, residency requirements, GDPR/CCPA DSR workflow, and telemetry consent UX.",
      "Define observability details: telemetry schema, redaction rules, consent propagation, batching/backoff, event volume caps, and offline buffering strategy.",
      "Propose evaluation/benchmark plan: representative tasks, success criteria, comparison of single-pass vs ReAct loops, and A/B framework with metrics.",
      "Include testing specifics: adversarial/prompt-injection suites, tool misuse fuzzing, network chaos tests, device battery/thermal profiling, and reproducible golden traces.",
      "Add rate-limiting/backoff and concurrency policies for both LLM calls and external tools, with retry/jitter strategies.",
      "Provide schema governance: versioning, migration strategy, compatibility guarantees, and rollout safeguards for contract changes.",
      "Set rollout schedule with phase dates, owners, resource plan, exit criteria (quantitative thresholds), and risk register with mitigations.",
      "Define caching policies (prompts/results/embeddings): TTLs, invalidation triggers, staleness handling, and encryption at rest/in transit."
    ]
  }
}